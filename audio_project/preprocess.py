# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u3_o-8mqxY8v5qXeIkd7zeNOexSOCvD7
"""

# 필수 라이브러리 설치
!pip install -q kagglehub librosa pandas numpy tqdm
!pip install resampy

"""**1. 데이터 다운로드 및 전처리**"""

import kagglehub
import os
import pandas as pd
import numpy as np
import librosa
from tqdm import tqdm
from google.colab import drive

# 2. 구글 드라이브 마운트 (전처리 결과를 저장 용도)
print("구글 드라이브 연동 시작")
drive.mount('/content/drive')

# 저장할 폴더 생성 (내 드라이브/25-2 ML_Project 폴더에 저장됨)
SAVE_PATH = "/content/drive/MyDrive/25-2 ML_Project"
if not os.path.exists(SAVE_PATH):
    os.makedirs(SAVE_PATH)
    print(f"드라이브에 폴더 생성 완료: {SAVE_PATH}")
else:
    print(f"저장 경로 확인: {SAVE_PATH}")

# 3. 데이터셋 다운로드 (Kaggle 서버 -> Colab 서버)
print("\n데이터셋 다운로드 중...")
path = kagglehub.dataset_download("chrisfilo/urbansound8k")
print(f"다운로드 완료! 경로: {path}")
print("폴더 안 내용:", os.listdir(path))   # 확인용

# 4. 전처리
AUDIO_PATH = path
METADATA_PATH = os.path.join(path, "UrbanSound8K.csv")
n_mfcc = 40
max_len = 174 # 약 4초 길이

def extract_features(file_name):
    try:
        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=4)
        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)

        if mfccs.shape[1] < max_len:
            pad_width = max_len - mfccs.shape[1]
            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')
        else:
            mfccs = mfccs[:, :max_len]

        return mfccs

    except Exception as e:
        print("에러 발생 파일:", file_name)
        print("에러 메시지:", e)
        return None

# 5. 전처리 실행
metadata = pd.read_csv(METADATA_PATH)
features = []
labels = []

print("\n전처리 시작...")

# 전체 데이터 처리
for index, row in tqdm(metadata.iterrows(), total=metadata.shape[0]):

    # 파일 경로 조합
    file_name = os.path.join(AUDIO_PATH, 'fold' + str(row["fold"]), str(row["slice_file_name"]))
    class_label = row["classID"]

    data = extract_features(file_name)

    if data is not None:
        features.append(data)
        labels.append(class_label)

# 6. 전처리 결과 저장
x = np.array(features)
y = np.array(labels)

print("\n전처리 결과를 구글 드라이브에 저장 중...")
np.save(os.path.join(SAVE_PATH, "x.npy"), x)
np.save(os.path.join(SAVE_PATH, "y.npy"), y)
print("저장 완료!")

print(f"X shape: {x.shape}") # 전체 오디오 파일 개수, MFCC 계수 개수, 시간 프레임 길이 -> 오디오를 행렬로 표현
print(f"Y shape: {y.shape}") # 각 오디오 파일은 1개의 클래스(정수)로 표현 -> 1차원

"""**2. Train / Valid / Test data split**"""

import numpy as np
import pandas as pd
import os

# 이미 만들어둔 전처리 결과 로드
x = np.load(os.path.join(SAVE_PATH, "x.npy"))
y = np.load(os.path.join(SAVE_PATH, "y.npy"))

metadata = pd.read_csv(METADATA_PATH)  # UrbanSound8K.csv
folds = metadata["fold"].values        # fold 정보 (1~10)

# 인덱스별로 구분
train_idx = np.where(np.isin(folds, [1,2,3,4,5,6,7,8]))[0]
val_idx   = np.where(folds == 9)[0]
test_idx  = np.where(folds == 10)[0]

# Dataset Split
x_train = x[train_idx]
y_train = y[train_idx]

x_val = x[val_idx]
y_val = y[val_idx]

x_test = x[test_idx]
y_test = y[test_idx]

print("Train:", x_train.shape, y_train.shape) # 대략 80%
print("Val:  ", x_val.shape, y_val.shape) # 대략 9%
print("Test: ", x_test.shape, y_test.shape) # 대략 10%

# 결과를 드라이브에 저장
np.save(os.path.join(SAVE_PATH, "X_train.npy"), x_train)
np.save(os.path.join(SAVE_PATH, "y_train.npy"), y_train)

np.save(os.path.join(SAVE_PATH, "X_val.npy"), x_val)
np.save(os.path.join(SAVE_PATH, "y_val.npy"), y_val)

np.save(os.path.join(SAVE_PATH, "X_test.npy"), x_test)
np.save(os.path.join(SAVE_PATH, "y_test.npy"), y_test)

print("모든 Split 저장 완료!")